{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kekenziii/Pengembangan-Sistem-Peramalan-Tingkat-Hunian-Hotel-Menggunakan-LightGBM/blob/main/Model_Pengembangan_Sistem_Peramalan_Tingkat_Hunian_Hotel_Menggunakan_LightGBM_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CQFBdnJEwQF"
      },
      "source": [
        "# Model Skripsi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8PGuWyHVIuJ"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yo9O9DmFBrx"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzkB6FVGWI80"
      },
      "outputs": [],
      "source": [
        "print(\"\\nHolidays\\n\")\n",
        "!pip install holidays # Buat data liburan di Indonesia\n",
        "\n",
        "print(\"\\nDarts\\n\")\n",
        "!pip install darts # Buat model\n",
        "\n",
        "print(\"\\Optuna\\n\")\n",
        "!pip install optuna # Parameter tuning\n",
        "# !pip install streamlit\n",
        "# !pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_gtI7eAL7Mc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWxiasnECuQz"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "import plotly.graph_objs as go # Buat plot sistem\n",
        "import holidays #Covariate\n",
        "import calendar # Dipake saat display rata2 occupancy rate bulan lalu. Mungkin bakal dihapus\n",
        "from datetime import timedelta\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import kurtosis, skew # Cek kurtosis dan skew\n",
        "import statsmodels.api as sm # ACF\n",
        "from darts import TimeSeries\n",
        "from darts.models import LightGBMModel # Model\n",
        "# from sklearn.model_selection import TimeSeriesSplit # Crossval\n",
        "from darts.metrics import mae, mape, rmse, mse\n",
        "from darts.metrics.metrics import smape\n",
        "\n",
        "import optuna # Parameter tuning\n",
        "\n",
        "import warnings # Biar gak diganggu warning\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Sistem\n",
        "# import streamlit as st # Streamlit\n",
        "# from pyngrok import ngrok # Deploy sistem web based\n",
        "# import plotly.graph_objs as go # Visualisasi dalam sistem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PnKpR32Do3H"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwaMOlsuDoPY"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oibUpCoHDdLe"
      },
      "outputs": [],
      "source": [
        "df_A = pd.read_csv('/content/drive/MyDrive/Skripsi/HotelA_Hotel_CSV.csv')\n",
        "df_B = pd.read_csv('/content/drive/MyDrive/Skripsi/HotelB_Hotel_CSV.csv')\n",
        "df_C = pd.read_csv('/content/drive/MyDrive/Skripsi/HotelC_Hotel_CSV.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLbOLVGwE08j"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzA_3xe-jmfY"
      },
      "source": [
        "## 1. Eksplorasi Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0-K62ympCs9"
      },
      "outputs": [],
      "source": [
        "print(df_A.shape)\n",
        "print(df_B.shape)\n",
        "print(df_C.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHg0O5d1EJI4"
      },
      "outputs": [],
      "source": [
        "df_A.info()\n",
        "df_B.info()\n",
        "df_C.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KsA6yD1ZAic"
      },
      "outputs": [],
      "source": [
        "df_A.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLE3BJZxRL9G"
      },
      "outputs": [],
      "source": [
        "df_A.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCPlqoZ-ZVcW"
      },
      "outputs": [],
      "source": [
        "df_B.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zXfzQiVZXN0"
      },
      "outputs": [],
      "source": [
        "df_C.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-KdROkGErEn"
      },
      "source": [
        "### Cek Null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spMPLiujELgh"
      },
      "outputs": [],
      "source": [
        "na_counts = {\n",
        "    'df_A': df_A.isna().sum(),\n",
        "    'df_B': df_B.isna().sum(),\n",
        "    'df_C': df_C.isna().sum()\n",
        "}\n",
        "\n",
        "na_counts_df = pd.DataFrame(na_counts)\n",
        "\n",
        "print(na_counts_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB0lMvIDEm_0"
      },
      "source": [
        "### Range Tanggal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I18j_6LYEd6Q"
      },
      "outputs": [],
      "source": [
        "df_A[\"Date\"] = pd.to_datetime(df_A[\"Date\"])\n",
        "df_B[\"Date\"] = pd.to_datetime(df_B[\"Date\"])\n",
        "df_C[\"Date\"] = pd.to_datetime(df_C[\"Date\"])\n",
        "\n",
        "date_ranges = pd.DataFrame({\n",
        "    \"Hotel\": [\"Hotel A\", \"Hotel B\", \"Hotel C\"],\n",
        "    \"From\": [df_A['Date'].min().strftime('%Y-%m-%d'), df_B['Date'].min().strftime('%Y-%m-%d'), df_C['Date'].min().strftime('%Y-%m-%d')],\n",
        "    \"To\": [df_A['Date'].max().strftime('%Y-%m-%d'), df_B['Date'].max().strftime('%Y-%m-%d'), df_C['Date'].max().strftime('%Y-%m-%d')]\n",
        "}).set_index('Hotel')\n",
        "\n",
        "print(tabulate(date_ranges, headers='keys'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dsqERxrtM95"
      },
      "outputs": [],
      "source": [
        "dfs = [df_A, df_B, df_C]\n",
        "labels = [\"Series A\", \"Series B\", \"Series C\"]\n",
        "\n",
        "global_min_date = min(df[\"Date\"].min() for df in dfs)\n",
        "global_max_date = max(df[\"Date\"].max() for df in dfs)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(60, 20), sharex=True)\n",
        "\n",
        "for i, (df, label) in enumerate(zip(dfs, labels)):\n",
        "    ax = axes[i]\n",
        "\n",
        "    ax.plot(df[\"Date\"], df[\"Occ (%) Sold\"], label=f\"{label} (Actual)\", color=f\"blue\", alpha=0.7)\n",
        "\n",
        "    rolling_avg = df[\"Occ (%) Sold\"].rolling(window=30).mean()\n",
        "    ax.plot(df[\"Date\"], rolling_avg, label=f\"{label} (3-day Avg)\", linestyle=\"dashed\", color=f\"red\")\n",
        "\n",
        "    ax.set_ylabel(label)\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "axes[-1].set_xlim(global_min_date, global_max_date)\n",
        "\n",
        "plt.xlabel(\"Date\")\n",
        "plt.suptitle(\"Three Time Series with Aligned X-Axis and 3-Day Rolling Average\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cKrTEIYSgfi"
      },
      "source": [
        "### Cek Outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B2kU3vcGUmL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 15))\n",
        "\n",
        "# Dataset A\n",
        "q1_A = df_A['Occ (%) Sold'].quantile(0.25)\n",
        "q3_A = df_A['Occ (%) Sold'].quantile(0.75)\n",
        "iqr_A = q3_A - q1_A\n",
        "lower_bound_A = q1_A - 1.5 * iqr_A\n",
        "upper_bound_A = q3_A + 1.5 * iqr_A\n",
        "outliers_A = df_A[(df_A['Occ (%) Sold'] < lower_bound_A) | (df_A['Occ (%) Sold'] > upper_bound_A)]\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.boxplot(df_A['Occ (%) Sold'], vert=False, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
        "plt.axvline(lower_bound_A, color='red', linestyle='--')\n",
        "plt.axvline(upper_bound_A, color='red', linestyle='--')\n",
        "plt.scatter(outliers_A['Occ (%) Sold'], [1] * len(outliers_A), color='orange', zorder=3, label='Outliers')\n",
        "plt.title(\"Outliers in Dataset A\", fontsize=40)\n",
        "plt.xlabel(\"Occ (%) Sold\", fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.legend()\n",
        "\n",
        "# Dataset B\n",
        "q1_B = df_B['Occ (%) Sold'].quantile(0.25)\n",
        "q3_B = df_B['Occ (%) Sold'].quantile(0.75)\n",
        "iqr_B = q3_B - q1_B\n",
        "lower_bound_B = q1_B - 1.5 * iqr_B\n",
        "upper_bound_B = q3_B + 1.5 * iqr_B\n",
        "outliers_B = df_B[(df_B['Occ (%) Sold'] < lower_bound_B) | (df_B['Occ (%) Sold'] > upper_bound_B)]\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.boxplot(df_B['Occ (%) Sold'], vert=False, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
        "plt.axvline(lower_bound_B, color='red', linestyle='--')\n",
        "plt.axvline(upper_bound_B, color='red', linestyle='--')\n",
        "plt.scatter(outliers_B['Occ (%) Sold'], [1] * len(outliers_B), color='orange', zorder=3, label='Outliers')\n",
        "plt.title(\"Outliers in Dataset B\", fontsize=40)\n",
        "plt.xlabel(\"Occ (%) Sold\", fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.legend()\n",
        "\n",
        "# Dataset C\n",
        "q1_C = df_C['Occ (%) Sold'].quantile(0.25)\n",
        "q3_C = df_C['Occ (%) Sold'].quantile(0.75)\n",
        "iqr_C = q3_C - q1_C\n",
        "lower_bound_C = q1_C - 1.5 * iqr_C\n",
        "upper_bound_C = q3_C + 1.5 * iqr_C\n",
        "outliers_C = df_C[(df_C['Occ (%) Sold'] < lower_bound_C) | (df_C['Occ (%) Sold'] > upper_bound_C)]\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.boxplot(df_C['Occ (%) Sold'], vert=False, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
        "plt.axvline(lower_bound_C, color='red', linestyle='--')\n",
        "plt.axvline(upper_bound_C, color='red', linestyle='--')\n",
        "plt.scatter(outliers_C['Occ (%) Sold'], [1] * len(outliers_C), color='orange', zorder=3, label='Outliers')\n",
        "plt.title(\"Outliers in Dataset C\", fontsize=40)\n",
        "plt.xlabel(\"Occ (%) Sold\", fontsize=20)\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqflGTa_HRkj"
      },
      "source": [
        "### Cek Kurtosis dan Skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwMNPLeoNzNj"
      },
      "outputs": [],
      "source": [
        "def check_kurtosis_and_skewness(df):\n",
        "    kurt = kurtosis(df['Occ (%) Sold'])\n",
        "    skw = skew(df['Occ (%) Sold'])\n",
        "\n",
        "    print(f\"Kurtosis: {kurt}\")\n",
        "    print(f\"Skewness: {skw}\")\n",
        "\n",
        "    if kurt > 0:\n",
        "        print(\"Distribution is leptokurtic (heavy tails).\")\n",
        "    elif kurt < 0:\n",
        "        print(\"Distribution is platykurtic (light tails).\")\n",
        "    else:\n",
        "        print(\"Distribution is mesokurtic (normal-like).\")\n",
        "\n",
        "    if skw > 0:\n",
        "        print(\"Data is positively skewed (long right tail).\\n\")\n",
        "    elif skw < 0:\n",
        "        print(\"Data is negatively skewed (long left tail).\\n\")\n",
        "    else:\n",
        "        print(\"Data is symmetric.\\n\")\n",
        "\n",
        "    return kurt, skw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egptHg0WN2B-"
      },
      "outputs": [],
      "source": [
        "kurt_A, skw_A = check_kurtosis_and_skewness(df_A)\n",
        "kurt_B, skw_B = check_kurtosis_and_skewness(df_B)\n",
        "kurt_C, skw_C = check_kurtosis_and_skewness(df_C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQYcS8NGfRaY"
      },
      "source": [
        "### Cek ACF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm6ejnxcfUxB"
      },
      "outputs": [],
      "source": [
        "datasets = [(\"A\", df_A), (\"B\", df_B), (\"C\", df_C)]\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 30))\n",
        "\n",
        "viable_lags = {}\n",
        "\n",
        "for i, (label, df) in enumerate(datasets):\n",
        "    series = df[\"Occ (%) Sold\"]\n",
        "\n",
        "    acf_values = sm.tsa.acf(series, nlags=196)\n",
        "    conf_interval = 1.96 / np.sqrt(len(series))\n",
        "\n",
        "    acf_lag = np.argmax((np.abs(acf_values[1:]) < conf_interval)) + 1\n",
        "    viable_lags[label] = acf_lag\n",
        "\n",
        "    sm.graphics.tsa.plot_acf(series, lags=196, ax=axes[i])\n",
        "    axes[i].set_title(f\"ACF - {label} (Lag: {acf_lag})\")\n",
        "    axes[i].axvline(acf_lag, color='r', linestyle='dashed')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "for dataset, lag in viable_lags.items():\n",
        "    print(f\"{dataset}: ACF Lag = {lag}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyvJiCss0Q19"
      },
      "source": [
        "### Visualisasi Pembagian Train dan Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE8Qid-40XXQ"
      },
      "outputs": [],
      "source": [
        "def plot_occupancy(df, hotel_name, color1='blue', color2='green'):\n",
        "    plt.figure(figsize=(25, 15))\n",
        "\n",
        "    split_index = int(len(df) * 0.8)\n",
        "\n",
        "    plt.plot(df[\"Date\"][:split_index], df[\"Occ (%) Sold\"][:split_index], marker='o', color=color1, label=f'{hotel_name} (Train)')\n",
        "\n",
        "    plt.plot(df[\"Date\"][split_index:], df[\"Occ (%) Sold\"][split_index:], marker='o', color=color2, label=f'{hotel_name} (Test)')\n",
        "\n",
        "    plt.axvline(x=df[\"Date\"].iloc[split_index], color='red', linestyle='--', linewidth=2, label='Train-Test Split')\n",
        "\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Occupancy Rate\")\n",
        "    plt.title(hotel_name)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_occupancy(df_A, \"Hotel A\")\n",
        "plot_occupancy(df_B, \"Hotel B\")\n",
        "plot_occupancy(df_C, \"Hotel C\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4xtzFyO0UMz"
      },
      "source": [
        "### Range Data Train dan Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIV-IiV-0Yi7"
      },
      "outputs": [],
      "source": [
        "def get_split_ranges(df, hotel_name):\n",
        "    split_index = int(len(df) * 0.8)\n",
        "\n",
        "    return {\n",
        "        \"Hotel\": hotel_name,\n",
        "        \"Train Start\": df[\"Date\"].iloc[0],\n",
        "        \"Train End\": df[\"Date\"].iloc[split_index - 1],\n",
        "        \"Test Start\": df[\"Date\"].iloc[split_index],\n",
        "        \"Test End\": df[\"Date\"].iloc[-1],\n",
        "    }\n",
        "\n",
        "split_table = pd.DataFrame([\n",
        "    get_split_ranges(df_A, \"Hotel A\"),\n",
        "    get_split_ranges(df_B, \"Hotel B\"),\n",
        "    get_split_ranges(df_C, \"Hotel C\"),\n",
        "])\n",
        "\n",
        "print(tabulate(split_table, headers='keys', tablefmt='grid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvGNbbI1vn5v"
      },
      "source": [
        "# 2. Pra-Pemrosesan Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjurjJfg_QJS"
      },
      "source": [
        "## Transformasi Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlcUAWtJvqrY"
      },
      "source": [
        "#### Visualisasi Sebelum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEhXBrGuFODw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25, 15))\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(df_A[\"Date\"], df_A[\"Occ (%) Sold\"], label='Hotel A', marker='o', color = 'purple')\n",
        "plt.xlabel(\"Date\", fontsize=30)\n",
        "plt.ylabel(\"Occupancy Rate\", fontsize=30)\n",
        "plt.title(\"Hotel A - Occupancy Percentage Over Time\", fontsize=50)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(df_B[\"Date\"], df_B[\"Occ (%) Sold\"], label='Hotel B', marker='o', color = 'blue')\n",
        "plt.xlabel(\"Date\", fontsize=30)\n",
        "plt.ylabel(\"Occupancy Rate\", fontsize=30)\n",
        "plt.title(\"Hotel B - Occupancy Percentage Over Time\", fontsize=50)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(df_C[\"Date\"], df_C[\"Occ (%) Sold\"], label='Hotel C', marker='o', color = 'green')\n",
        "plt.xlabel(\"Date\", fontsize=30)\n",
        "plt.ylabel(\"Occupancy Rate\", fontsize=30)\n",
        "plt.title(\"Hotel C - Occupancy Percentage Over Time\", fontsize=50)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSrl1rcFPlLK"
      },
      "source": [
        "### Rekayasa Fitur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ODdr3K5zJ0j"
      },
      "outputs": [],
      "source": [
        "def reductions(df_list):\n",
        "    for i, df in enumerate(df_list):\n",
        "        df_list[i] = df[[\"Date\", \"Occ (%) Sold\"]]\n",
        "\n",
        "df_list = [df_A, df_B, df_C]\n",
        "reductions(df_list)\n",
        "\n",
        "df_A, df_B, df_C = df_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG0hjQPd1mpH"
      },
      "outputs": [],
      "source": [
        "def add_holiday_feature(df, date_column='Date'):\n",
        "    indonesia_holidays = holidays.Indonesia()\n",
        "    df[date_column] = pd.to_datetime(df[date_column])\n",
        "\n",
        "    df['is_holiday'] = df[date_column].apply(lambda x: x in indonesia_holidays or x.weekday() in [5, 6])\n",
        "    return df\n",
        "\n",
        "def prepare_data(df):\n",
        "    df = add_holiday_feature(df)\n",
        "\n",
        "    df['day_of_week'] = df['Date'].dt.weekday\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['week_of_year'] = df['Date'].dt.isocalendar().week\n",
        "\n",
        "    df_prepared = df[['Date', 'is_holiday', 'day_of_week', 'month', 'week_of_year', 'Occ (%) Sold']]\n",
        "    return df_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdxOX1eC424M"
      },
      "outputs": [],
      "source": [
        "df_A_prepared = prepare_data(df_A)\n",
        "df_B_prepared = prepare_data(df_B)\n",
        "df_C_prepared = prepare_data(df_C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhAeCRJknVX"
      },
      "source": [
        "### Mengatur Data Abnormal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3Y3v4RgqtHU"
      },
      "outputs": [],
      "source": [
        "def transformation(df, method=\"boxcox\", Hotel=\"Hotel A\"):\n",
        "    df_transformed = df.copy()\n",
        "    split_index = int(len(df) * 0.8)\n",
        "\n",
        "    if method == \"log\":\n",
        "        df_transformed['Occ (%) Sold'] = df_transformed['Occ (%) Sold'].apply(lambda x: np.log(x) if x > 0 else 0)\n",
        "\n",
        "    elif method == \"sqrt\":\n",
        "        df_transformed['Occ (%) Sold'] = df_transformed['Occ (%) Sold'].apply(lambda x: np.sqrt(x) if x >= 0 else 0)\n",
        "\n",
        "    elif method == \"boxcox\":\n",
        "        df_transformed['Occ (%) Sold'] += 1\n",
        "        transformed_values, lambda_value = stats.boxcox(df_transformed['Occ (%) Sold'].values)\n",
        "        df_transformed['Occ (%) Sold'] = transformed_values\n",
        "        print(f\"{Hotel} Box-Cox Lambda: {lambda_value}\")\n",
        "\n",
        "    elif method == \"moving_avg\":\n",
        "        df_transformed.loc[:split_index, 'Occ (%) Sold'] = df_transformed.loc[:split_index, 'Occ (%) Sold'].rolling(window=2, min_periods=1).mean()\n",
        "\n",
        "    elif method == \"No\":\n",
        "        return df_transformed\n",
        "\n",
        "    return df_transformed\n",
        "\n",
        "# df_A_prepared = transformation(df_A_prepared, method=\"moving_avg\", Hotel=\"Hotel A\")\n",
        "# df_B_prepared = transformation(df_B_prepared, method=\"moving_avg\", Hotel=\"Hotel B\")\n",
        "# df_C_prepared = transformation(df_C_prepared, method=\"moving_avg\", Hotel=\"Hotel C\")\n",
        "\n",
        "df_A_edited = transformation(df_A_prepared, method=\"none\", Hotel=\"Hotel A\")\n",
        "df_B_edited = transformation(df_B_prepared, method=\"none\", Hotel=\"Hotel B\")\n",
        "df_C_edited = transformation(df_C_prepared, method=\"none\", Hotel=\"Hotel C\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs6oGXxbff5c"
      },
      "outputs": [],
      "source": [
        "print(f\"Hotel A training data shape: {df_A_edited.info()}\")\n",
        "print(f\"Hotel B training data shape: {df_B_edited.info()}\")\n",
        "print(f\"Hotel C training data shape: {df_C_edited.info()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eey-k-kXOx06"
      },
      "outputs": [],
      "source": [
        "kurt_A, skw_A = check_kurtosis_and_skewness(df_A_edited)\n",
        "kurt_B, skw_B = check_kurtosis_and_skewness(df_B_edited)\n",
        "kurt_C, skw_C = check_kurtosis_and_skewness(df_C_edited)\n",
        "\n",
        "prepared_a = df_A_edited.copy()\n",
        "prepared_b = df_B_edited.copy()\n",
        "prepared_c = df_C_edited.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDi8wOfw_EPe"
      },
      "outputs": [],
      "source": [
        "prepared_a[\"Occ (%) Sold\"].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pemodelan"
      ],
      "metadata": {
        "id": "Rh4iXRacclbN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0y4Sl6kE7uk"
      },
      "source": [
        "## Inverse Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou2C9GbWRQtW"
      },
      "outputs": [],
      "source": [
        "def inverse_log_transform(series):\n",
        "    return TimeSeries.from_dataframe(series.pd_dataframe().apply(np.exp))\n",
        "\n",
        "def inverse_sqrt_transform(series):\n",
        "    return TimeSeries.from_dataframe(series.pd_dataframe().apply(lambda x: x**2))\n",
        "\n",
        "def inverse_boxcox_transform(series, lambda_value):\n",
        "    return TimeSeries.from_dataframe(series.pd_dataframe().apply(lambda x: (lambda_value * x + 1) ** (1 / lambda_value)))\n",
        "\n",
        "\n",
        "def inverse_transform(pred, target, method, lambda_value=None):\n",
        "    if method == \"log\":\n",
        "        return inverse_log_transform(pred), inverse_log_transform(target)\n",
        "    elif method == \"sqrt\":\n",
        "        return inverse_sqrt_transform(pred), inverse_sqrt_transform(target)\n",
        "    elif method == \"boxcox\":\n",
        "        if lambda_value is None:\n",
        "            raise ValueError(\"Lambda value is required for Box-Cox transformation.\")\n",
        "        return inverse_boxcox_transform(pred, lambda_value), inverse_boxcox_transform(target, lambda_value)\n",
        "    elif method == \"none\":\n",
        "        return pred, target\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown transformation method: {method}\")\n",
        "\n",
        "\n",
        "# lambda_value_a = 0.7886837783709969\n",
        "# lambda_value_b = 1.023992820766559\n",
        "# lambda_value_c = 0.8310669031702983"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRd5jNY8hRsT"
      },
      "source": [
        "## Lags, Based on ACF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spBZhIKwhPBQ"
      },
      "outputs": [],
      "source": [
        "lags_A = 17\n",
        "lags_B = 23\n",
        "lags_C = 17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNEbpGaskWz3"
      },
      "source": [
        "## (1) No Optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4wfW47Vkb4M"
      },
      "source": [
        "### (1A) Model A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwdtfKXGlIbZ"
      },
      "outputs": [],
      "source": [
        "series_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_a_lightGBM) * 0.8)\n",
        "target_train_a_lightGBM, target_test_a_lightGBM = series_a_lightGBM[:split_index], series_a_lightGBM[split_index:]\n",
        "future_cov_train_a_lightGBM, future_cov_test_a_lightGBM = future_covariates_a_lightGBM[:split_index], future_covariates_a_lightGBM[split_index:]\n",
        "\n",
        "model_a_lightGBM = LightGBMModel(\n",
        "    lags=lags_A,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "model_a_lightGBM.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "backtest_predictions_a_lightGBM = model_a_lightGBM.historical_forecasts(\n",
        "    series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "    future_covariates=future_covariates_a_lightGBM,\n",
        "    start=len(target_train_a_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "mae_value_a_lightGBM = mae(target_test_a_lightGBM, backtest_predictions_a_lightGBM)\n",
        "smape_value_a_lightGBM = smape(target_test_a_lightGBM, backtest_predictions_a_lightGBM)\n",
        "rmse_value_a_lightGBM = rmse(target_test_a_lightGBM, backtest_predictions_a_lightGBM)\n",
        "\n",
        "print(f\"\\nMAE: {mae_value_a_lightGBM:.4f}\")\n",
        "print(f\"SMAPE: {smape_value_a_lightGBM:.4f}%\")\n",
        "print(f\"RMSE: {rmse_value_a_lightGBM:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vmrpE7ekdOm"
      },
      "source": [
        "### (1B) Model B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qh6tGedPlTHU"
      },
      "outputs": [],
      "source": [
        "series_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_b_lightGBM) * 0.8)\n",
        "target_train_b_lightGBM, target_test_b_lightGBM = series_b_lightGBM[:split_index], series_b_lightGBM[split_index:]\n",
        "future_cov_train_b_lightGBM, future_cov_test_b_lightGBM = future_covariates_b_lightGBM[:split_index], future_covariates_b_lightGBM[split_index:]\n",
        "\n",
        "model_b_lightGBM = LightGBMModel(\n",
        "    lags=lags_B,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "model_b_lightGBM.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "backtest_predictions_b_lightGBM = model_b_lightGBM.historical_forecasts(\n",
        "    series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "    future_covariates=future_covariates_b_lightGBM,\n",
        "    start=len(target_train_b_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "mae_value_b_lightGBM = mae(target_test_b_lightGBM, backtest_predictions_b_lightGBM)\n",
        "smape_value_b_lightGBM = smape(target_test_b_lightGBM, backtest_predictions_b_lightGBM)\n",
        "rmse_value_b_lightGBM = rmse(target_test_b_lightGBM, backtest_predictions_b_lightGBM)\n",
        "\n",
        "print(f\"\\nMAE: {mae_value_b_lightGBM:.4f}\")\n",
        "print(f\"SMAPE: {smape_value_b_lightGBM:.4f}%\")\n",
        "print(f\"RMSE: {rmse_value_b_lightGBM:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5dR5pHyki7t"
      },
      "source": [
        "### (1C) Model C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eymY1GzllVKX"
      },
      "outputs": [],
      "source": [
        "series_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_c_lightGBM) * 0.8)\n",
        "target_train_c_lightGBM, target_test_c_lightGBM = series_c_lightGBM[:split_index], series_c_lightGBM[split_index:]\n",
        "future_cov_train_c_lightGBM, future_cov_test_c_lightGBM = future_covariates_c_lightGBM[:split_index], future_covariates_c_lightGBM[split_index:]\n",
        "\n",
        "model_c_lightGBM = LightGBMModel(\n",
        "    lags=lags_C,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "model_c_lightGBM.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "backtest_predictions_c_lightGBM = model_c_lightGBM.historical_forecasts(\n",
        "    series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "    future_covariates=future_covariates_c_lightGBM,\n",
        "    start=len(target_train_c_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "mae_value_c_lightGBM = mae(target_test_c_lightGBM, backtest_predictions_c_lightGBM)\n",
        "smape_value_c_lightGBM = smape(target_test_c_lightGBM, backtest_predictions_c_lightGBM)\n",
        "rmse_value_c_lightGBM = rmse(target_test_c_lightGBM, backtest_predictions_c_lightGBM)\n",
        "\n",
        "print(f\"\\nMAE: {mae_value_c_lightGBM:.4f}\")\n",
        "print(f\"SMAPE: {smape_value_c_lightGBM:.4f}%\")\n",
        "print(f\"RMSE: {rmse_value_c_lightGBM:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd77PDfwkpJU"
      },
      "source": [
        "## (2) Optuna, 50 Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83AGXZeLk_LK"
      },
      "source": [
        "#### (2A) Model A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB_fOxPVlvZ3"
      },
      "outputs": [],
      "source": [
        "series_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_a_lightGBM) * 0.8)\n",
        "target_train_a_lightGBM, target_test_a_lightGBM = series_a_lightGBM[:split_index], series_a_lightGBM[split_index:]\n",
        "future_cov_train_a_lightGBM, future_cov_test_a_lightGBM = future_covariates_a_lightGBM[:split_index], future_covariates_a_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_A,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "        future_covariates=future_covariates_a_lightGBM,\n",
        "        start=len(target_train_a_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_a_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_A,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "    future_covariates=future_covariates_a_lightGBM,\n",
        "    start=len(target_train_a_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_a_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_a_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_a_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STJqdFy4lsPY"
      },
      "source": [
        "### (2B) Model B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eYHmNEXgl7sp"
      },
      "outputs": [],
      "source": [
        "series_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_b_lightGBM) * 0.8)\n",
        "target_train_b_lightGBM, target_test_b_lightGBM = series_b_lightGBM[:split_index], series_b_lightGBM[split_index:]\n",
        "future_cov_train_b_lightGBM, future_cov_test_b_lightGBM = future_covariates_b_lightGBM[:split_index], future_covariates_b_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_B,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "        future_covariates=future_covariates_b_lightGBM,\n",
        "        start=len(target_train_b_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_b_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_B,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "    future_covariates=future_covariates_b_lightGBM,\n",
        "    start=len(target_train_b_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_b_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_b_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_b_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F7OsJ49ltua"
      },
      "source": [
        "### (2C) Model C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP9sB4p7mFXJ"
      },
      "outputs": [],
      "source": [
        "series_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_c_lightGBM) * 0.8)\n",
        "target_train_c_lightGBM, target_test_c_lightGBM = series_c_lightGBM[:split_index], series_c_lightGBM[split_index:]\n",
        "future_cov_train_c_lightGBM, future_cov_test_c_lightGBM = future_covariates_c_lightGBM[:split_index], future_covariates_c_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_C,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "        future_covariates=future_covariates_c_lightGBM,\n",
        "        start=len(target_train_c_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_c_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_C,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "    future_covariates=future_covariates_c_lightGBM,\n",
        "    start=len(target_train_c_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_c_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_c_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_c_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2yXBVzwktxq"
      },
      "source": [
        "## (3) Optuna, 100 Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmElJ8K7mq3t"
      },
      "source": [
        "### (3A) Model A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "17ir0cNqIStj"
      },
      "outputs": [],
      "source": [
        "series_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_a_lightGBM) * 0.8)\n",
        "target_train_a_lightGBM, target_test_a_lightGBM = series_a_lightGBM[:split_index], series_a_lightGBM[split_index:]\n",
        "future_cov_train_a_lightGBM, future_cov_test_a_lightGBM = future_covariates_a_lightGBM[:split_index], future_covariates_a_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_A,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "        future_covariates=future_covariates_a_lightGBM,\n",
        "        start=len(target_train_a_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_a_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_A,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "    future_covariates=future_covariates_a_lightGBM,\n",
        "    start=len(target_train_a_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_a_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_a_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_a_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihfXci5xm1sq"
      },
      "source": [
        "### (3B) Model B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUQ5mq_uwZmj"
      },
      "outputs": [],
      "source": [
        "series_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_b_lightGBM) * 0.8)\n",
        "target_train_b_lightGBM, target_test_b_lightGBM = series_b_lightGBM[:split_index], series_b_lightGBM[split_index:]\n",
        "future_cov_train_b_lightGBM, future_cov_test_b_lightGBM = future_covariates_b_lightGBM[:split_index], future_covariates_b_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_B,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "        future_covariates=future_covariates_b_lightGBM,\n",
        "        start=len(target_train_b_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_b_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_B,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "    future_covariates=future_covariates_b_lightGBM,\n",
        "    start=len(target_train_b_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_b_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_b_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_b_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CujAgSlnFAf"
      },
      "source": [
        "### (3C) Model C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q5AXEmUpvxuf"
      },
      "outputs": [],
      "source": [
        "series_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_c_lightGBM) * 0.8)\n",
        "target_train_c_lightGBM, target_test_c_lightGBM = series_c_lightGBM[:split_index], series_c_lightGBM[split_index:]\n",
        "future_cov_train_c_lightGBM, future_cov_test_c_lightGBM = future_covariates_c_lightGBM[:split_index], future_covariates_c_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_C,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "\n",
        "    model.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "        future_covariates=future_covariates_c_lightGBM,\n",
        "        start=len(target_train_c_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_c_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_C,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "    future_covariates=future_covariates_c_lightGBM,\n",
        "    start=len(target_train_c_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_c_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_c_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_c_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQqn4setn3UW"
      },
      "source": [
        "## (4) Optuna, 150 Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYcuRhHyn6A4"
      },
      "source": [
        "#### (4A) Model A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx2gHMTTn8aW"
      },
      "outputs": [],
      "source": [
        "series_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_a_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_a,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_a_lightGBM) * 0.8)\n",
        "target_train_a_lightGBM, target_test_a_lightGBM = series_a_lightGBM[:split_index], series_a_lightGBM[split_index:]\n",
        "future_cov_train_a_lightGBM, future_cov_test_a_lightGBM = future_covariates_a_lightGBM[:split_index], future_covariates_a_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_A,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "        future_covariates=future_covariates_a_lightGBM,\n",
        "        start=len(target_train_a_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_a_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_A,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_a_lightGBM, future_covariates=future_cov_train_a_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_a_lightGBM.concatenate(target_test_a_lightGBM),\n",
        "    future_covariates=future_covariates_a_lightGBM,\n",
        "    start=len(target_train_a_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_a_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_a_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_a_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Twjb89n-rL"
      },
      "source": [
        "#### (4B) Model B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRv_v8GOoAOn"
      },
      "outputs": [],
      "source": [
        "series_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_b_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_b,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_b_lightGBM) * 0.8)\n",
        "target_train_b_lightGBM, target_test_b_lightGBM = series_b_lightGBM[:split_index], series_b_lightGBM[split_index:]\n",
        "future_cov_train_b_lightGBM, future_cov_test_b_lightGBM = future_covariates_b_lightGBM[:split_index], future_covariates_b_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_B,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "        future_covariates=future_covariates_b_lightGBM,\n",
        "        start=len(target_train_b_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_b_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_B,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_b_lightGBM, future_covariates=future_cov_train_b_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_b_lightGBM.concatenate(target_test_b_lightGBM),\n",
        "    future_covariates=future_covariates_b_lightGBM,\n",
        "    start=len(target_train_b_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_b_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_b_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_b_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkiOE09JoCHo"
      },
      "source": [
        "#### (4C) Model C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjBZHysaoDoe"
      },
      "outputs": [],
      "source": [
        "series_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['Occ (%) Sold'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "future_covariates_c_lightGBM = TimeSeries.from_dataframe(\n",
        "    prepared_c,\n",
        "    time_col='Date',\n",
        "    value_cols=['is_holiday', 'day_of_week', 'month', 'week_of_year'],\n",
        "    fill_missing_dates=True\n",
        ")\n",
        "\n",
        "split_index = int(len(series_c_lightGBM) * 0.8)\n",
        "target_train_c_lightGBM, target_test_c_lightGBM = series_c_lightGBM[:split_index], series_c_lightGBM[split_index:]\n",
        "future_cov_train_c_lightGBM, future_cov_test_c_lightGBM = future_covariates_c_lightGBM[:split_index], future_covariates_c_lightGBM[split_index:]\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 450),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 7, 2047)\n",
        "    }\n",
        "\n",
        "    model = LightGBMModel(\n",
        "        lags=lags_C,\n",
        "        lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "        output_chunk_length=28,\n",
        "        verbose=-1,\n",
        "        random_state=42,\n",
        "        **params\n",
        "    )\n",
        "\n",
        "    model.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "    backtest_predictions = model.historical_forecasts(\n",
        "        series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "        future_covariates=future_covariates_c_lightGBM,\n",
        "        start=len(target_train_c_lightGBM),\n",
        "        forecast_horizon=28,\n",
        "        stride=28,\n",
        "        retrain=False,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return smape(target_test_c_lightGBM, backtest_predictions)\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "best_model = LightGBMModel(\n",
        "    lags=lags_C,\n",
        "    lags_future_covariates=[0, 1, 2, 3, 4, 5, 6],\n",
        "    output_chunk_length=28,\n",
        "    verbose=-1,\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "best_model.fit(target_train_c_lightGBM, future_covariates=future_cov_train_c_lightGBM)\n",
        "\n",
        "final_predictions = best_model.historical_forecasts(\n",
        "    series=target_train_c_lightGBM.concatenate(target_test_c_lightGBM),\n",
        "    future_covariates=future_covariates_c_lightGBM,\n",
        "    start=len(target_train_c_lightGBM),\n",
        "    forecast_horizon=28,\n",
        "    stride=28,\n",
        "    retrain=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_mae = mae(target_test_c_lightGBM, final_predictions)\n",
        "final_smape = smape(target_test_c_lightGBM, final_predictions)\n",
        "final_rmse = rmse(target_test_c_lightGBM, final_predictions)\n",
        "\n",
        "print(f\"\\nFinal MAE: {final_mae:.4f}\")\n",
        "print(f\"Final SMAPE: {final_smape:.4f}%\")\n",
        "print(f\"Final RMSE: {final_rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R83piHL6517o"
      },
      "source": [
        "# Streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo1oiICMDoOR"
      },
      "source": [
        "Token Kent: 2njmUSZRKuXEy8GSPANSix1cCzf_v5xQATTAzUkpeRWNwSiU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faElJNsRVXwC"
      },
      "source": [
        "https://colab.research.google.com/drive/15VwwLhZsWJtFCCpT6VGWE3zQdoYr8Z6K?usp=sharing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}